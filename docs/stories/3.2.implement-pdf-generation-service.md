# Story 3.2: Implement PDF Generation Service

## Status
Draft

## Story
**As a** legal evidence specialist working with the violation report generation system,
**I want** a new service that takes Violation objects and generates professional multi-page PDF reports with summary and detail pages including visual bark intensity graphs,
**so that** I can produce legally-compliant PDF violation reports that are professional, detailed, and ready for submission to municipal authorities.

## Acceptance Criteria
1. Create a new PDF generation service that accepts a list of `Violation` objects as input
2. Generate a professional multi-page PDF report containing both summary and detail pages
3. Include visual bark intensity graphs in the PDF using the bark event data
4. Render all content as a single PDF file with proper formatting and layout
5. Handle cases where bark intensity data is missing by using default intensity values
6. Ensure the PDF generation service is testable and maintainable with proper error handling

## Tasks / Subtasks
- [ ] Task 1: Research and select PDF generation library (AC: 1, 4)
  - [ ] Evaluate Python PDF libraries (reportlab, fpdf, weasyprint)
  - [ ] Select library based on features, maintenance, and complexity
  - [ ] Add dependency to project requirements
- [ ] Task 2: Design PDF report structure and layout (AC: 2, 4)
  - [ ] Define multi-page report structure (summary + detail pages)
  - [ ] Design page layouts with proper formatting
  - [ ] Create templates for consistent styling
- [ ] Task 3: Implement core PDF generation service (AC: 1, 2, 4)
  - [ ] Create new `bark_detector/utils/pdf_generator.py` module
  - [ ] Implement `PDFGenerationService` class with main generation method
  - [ ] Add proper error handling and logging
- [ ] Task 4: Implement summary page generation (AC: 2, 4)
  - [ ] Generate violation summary with key statistics
  - [ ] Include violation count, date ranges, and severity information
  - [ ] Format data in professional table layout
- [ ] Task 5: Implement detail pages generation (AC: 2, 4)
  - [ ] Generate individual violation detail pages
  - [ ] Include timestamp, duration, and bark event details
  - [ ] Format with consistent styling and readability
- [ ] Task 6: Implement visual bark intensity graphs (AC: 3, 5)
  - [ ] Create graph generation functionality using matplotlib or similar
  - [ ] Generate intensity graphs from bark event data
  - [ ] Handle missing intensity data with default values and clear labeling
  - [ ] Embed graphs properly in PDF pages
- [ ] Task 7: Implement comprehensive unit tests (AC: 6)
  - [ ] Test PDF generation with various violation scenarios
  - [ ] Test error handling for invalid data
  - [ ] Test graph generation with and without intensity data
  - [ ] Mock PDF library for faster test execution
- [ ] Task 8: Integration testing and validation (AC: 4, 6)
  - [ ] Test with real violation data from existing JSON files
  - [ ] Validate PDF output format and readability
  - [ ] Ensure proper multi-page layout and navigation

## Dev Notes

### Previous Story Insights
Story 3.1 successfully unified violation data models, creating a single source of truth with the `Violation` model and presentation-layer `ViolationReport`. The PDF generation service will consume the unified `Violation` objects directly, eliminating the need for data conversion and leveraging the clean data architecture.

### Data Models
**Unified Violation Model** [Source: architecture/data-models-and-schema-changes.md]:
- `Violation`: Primary data model with attributes: `violation_id`, `violation_type`, `violation_date`, `violation_start_time`, `violation_end_time`, `bark_event_ids`
- `PersistedBarkEvent`: Raw event data with attributes: `realworld_date`, `realworld_time`, `bark_id`, `bark_type`, `est_dog_size`, `audio_file_name`, `bark_audiofile_timestamp`, `confidence`, `intensity`
- Schema generates two files per analysis day: `[YYYY-MM-DD]_events.json` and `[YYYY-MM-DD]_violations.json`

**Data Integration Strategy** [Source: architecture/data-models-and-schema-changes.md]:
- PDF service will read data directly from `ViolationDatabase` using unified models
- `ViolationReport` model is now presentation-layer object, generated on-the-fly from raw `Violation` data
- Bark intensity data available from `PersistedBarkEvent.intensity` field

### Component Specifications
**New PDF Generation Component** [Source: architecture/component-architecture.md]:
- Location: `bark_detector/utils/pdf_generator.py` (following reporting layer pattern)
- Integration: Will be consumed by `bark_detector/utils/report_generator.py` for PDF output
- Data Source: Reads exclusively from `ViolationDatabase` via unified data models
- Dependencies: Will add PDF generation library (reportlab or similar) to tech stack

**Component Interaction** [Source: architecture/component-architecture.md]:
- CLI → Reporter → PDFGenerator → PDF File output
- PDFGenerator → ViolationDatabase (for violation and event data)
- Reporter will orchestrate PDF generation and file saving

### File Locations
**Source Tree Structure** [Source: architecture/source-tree.md]:
- New PDF generator: `bark_detector/utils/pdf_generator.py`
- Integration point: `bark_detector/utils/report_generator.py` (existing)
- Test location: `tests/test_utils/` for PDF generation tests
- Output location: `reports/` directory for generated PDF files
- Data sources: `violations/<date>/` containing JSON files

### Testing Requirements
**Test Organization** [Source: architecture/source-tree.md]:
- PDF generation tests: `tests/test_utils/` (alongside existing report_generator tests)
- Integration tests: `tests/test_integration/` for CLI-level PDF generation
- Fixture data: `tests/fixtures/` for test violation data

**Testing Standards** [Source: architecture/coding-standards.md]:
- Run `uv run pytest` locally before publishing changes
- Use fixture data or trimmed real-world JSON samples from `violations/` directory
- Include CLI smoke tests for PDF generation features
- Mock PDF library dependencies for faster test execution
- Target high-value coverage prioritizing PDF generation and error handling paths

### Technical Constraints
**Evidence Preservation** [Source: architecture/coding-standards.md]:
- PDF generation must preserve integrity of violation evidence (timestamps, ordering, confidence scores)
- Analysis pipelines must produce repeatable results across different machines
- PDF output must maintain backward compatibility with existing violation data

**Python Standards** [Source: architecture/coding-standards.md]:
- Use dataclasses for PDF configuration and structured data
- Prefer type hints on public functions
- Handle filesystem paths with `pathlib.Path`
- Route messages through configured logging instance
- Execute through `uv run` for dependency management

**Technology Stack** [Source: architecture/tech-stack.md]:
- Primary language: Python 3.11.4 (supports >=3.9,<3.12)
- New dependency: PDF generation library (reportlab, fpdf, or weasyprint)
- Graph generation: Consider matplotlib or similar for bark intensity visualizations
- Package management: `uv` for all dependency installation and execution

### Project Structure Notes
The PDF generation service aligns well with the existing architecture, extending the utilities layer alongside `report_generator.py`. The service will integrate cleanly with the unified data models from Story 3.1 and prepare for CLI integration in Story 3.3.

## Testing
**Test Location**: `tests/test_utils/`
**Test Standards**:
- Use pytest framework with `uv run pytest` execution
- Focus on PDF generation, graph rendering, and error handling paths
- Mock PDF library for faster test execution and consistent output validation
- Use fixture data from `tests/fixtures/` or real-world JSON samples from `violations/`
**Testing Requirements**:
- Verify PDF generation with various violation scenarios (single violations, multiple violations, edge cases)
- Test graph generation with complete intensity data and missing/incomplete data
- Validate error handling for invalid violation data and file system issues
- Ensure PDF output format consistency and readability across different input data sets

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2025-09-24 | 1.0 | Initial story creation based on Epic 3 Story 2 | Bob (Scrum Master) |

## Dev Agent Record
*This section will be populated by the development agent during implementation*

### Agent Model Used
*To be filled by dev agent*

### Debug Log References
*To be filled by dev agent*

### Completion Notes List
*To be filled by dev agent*

### File List
*To be filled by dev agent*

## QA Results
*This section will be populated by the QA agent during review*
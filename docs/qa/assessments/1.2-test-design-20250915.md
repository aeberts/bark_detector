# Test Design: Story 1.2

Date: 2025-09-15
Designer: Quinn (Test Architect)

## Test Strategy Overview

- Total test scenarios: 22
- Unit tests: 12 (55%)
- Integration tests: 8 (36%)
- E2E tests: 2 (9%)
- Priority distribution: P0: 8, P1: 10, P2: 4

**Risk-Driven Focus**: Heavy emphasis on data integrity testing (P0) to mitigate DATA-001 high-risk finding.

## Test Scenarios by Acceptance Criteria

### AC1: LegalViolationTracker saves all detected raw bark events to the correct [YYYY-MM-DD]_events.json file

#### Scenarios

| ID           | Level       | Priority | Test                                    | Justification                              |
| ------------ | ----------- | -------- | --------------------------------------- | ------------------------------------------ |
| 1.2-UNIT-001 | Unit        | P0       | Map bark detection to PersistedBarkEvent | Pure data transformation logic             |
| 1.2-UNIT-002 | Unit        | P0       | Generate unique bark_id for each event | Core identification logic                  |
| 1.2-UNIT-003 | Unit        | P1       | Extract bark_type from YAMNet results  | Classification logic validation            |
| 1.2-UNIT-004 | Unit        | P1       | Calculate bark_audiofile_timestamp     | Audio correlation timestamp logic          |
| 1.2-UNIT-005 | Unit        | P1       | Include confidence/intensity metrics    | Detection metrics mapping                  |
| 1.2-INT-001  | Integration | P0       | Events saved to correct date-based file | Multi-component file persistence workflow  |
| 1.2-INT-002  | Integration | P0       | Atomic save operation with rollback     | Prevent data corruption (mitigates DATA-001) |
| 1.2-INT-003  | Integration | P1       | Handle missing recordings directory     | Error handling for filesystem issues       |

**Risk Coverage**: Mitigates DATA-001 (data persistence corruption) through atomic operations and validation testing.

### AC2: It saves all identified bylaw violations to the correct [YYYY-MM-DD]_violations.json file

#### Scenarios

| ID           | Level       | Priority | Test                                      | Justification                              |
| ------------ | ----------- | -------- | ----------------------------------------- | ------------------------------------------ |
| 1.2-UNIT-006 | Unit        | P0       | Map violation detection to Violation model | Pure data transformation logic             |
| 1.2-UNIT-007 | Unit        | P0       | Generate unique violation_id              | Core identification logic                  |
| 1.2-UNIT-008 | Unit        | P1       | Create bark_event_ids array references   | Event correlation logic                    |
| 1.2-UNIT-009 | Unit        | P1       | Format violation start/end times         | Timestamp formatting logic                 |
| 1.2-UNIT-010 | Unit        | P1       | Classify violation_type (Constant/Intermittent) | Classification algorithm validation     |
| 1.2-INT-004  | Integration | P0       | Violations saved to correct date-based file | Multi-component file persistence workflow  |
| 1.2-INT-005  | Integration | P0       | Event-violation correlation maintained    | Data relationship integrity (mitigates DATA-001) |
| 1.2-INT-006  | Integration | P1       | Handle corrupted audio files gracefully  | Error handling for malformed data          |

**Risk Coverage**: Addresses DATA-001 through relationship validation and error handling for corrupted data.

### AC3: The CHANGELOG.md is updated with a summary of the refactor

#### Scenarios

| ID           | Level       | Priority | Test                                  | Justification                          |
| ------------ | ----------- | -------- | ------------------------------------- | -------------------------------------- |
| 1.2-UNIT-011 | Unit        | P2       | Validate CHANGELOG entry format       | Documentation format validation        |
| 1.2-UNIT-012 | Unit        | P2       | Verify refactor summary completeness  | Documentation content validation       |

### Integration Verification: CLI workflow functions correctly

#### Scenarios

| ID           | Level       | Priority | Test                                    | Justification                              |
| ------------ | ----------- | -------- | --------------------------------------- | ------------------------------------------ |
| 1.2-INT-007  | Integration | P0       | --analyze-violations command success    | Critical user journey (mitigates TECH-001) |
| 1.2-INT-008  | Integration | P1       | Date-based directory creation           | Filesystem integration workflow            |
| 1.2-E2E-001  | E2E         | P0       | End-to-end analysis workflow            | Complete system validation                 |
| 1.2-E2E-002  | E2E         | P1       | Analysis accuracy vs legacy             | Regression protection                      |

**Risk Coverage**: Addresses TECH-001 (integration complexity) through comprehensive workflow validation.

### Cross-Cutting Concerns

#### Error Handling & Data Integrity

| ID           | Level       | Priority | Test                                    | Justification                              |
| ------------ | ----------- | -------- | --------------------------------------- | ------------------------------------------ |
| 1.2-INT-009  | Integration | P2       | File system permission errors          | Operational robustness                     |
| 1.2-INT-010  | Integration | P2       | Malformed JSON recovery                 | Data corruption recovery                   |

## Risk Coverage

### DATA-001: Data Persistence Corruption/Failure (High Risk)
**Test Coverage**: 1.2-INT-001, 1.2-INT-002, 1.2-INT-004, 1.2-INT-005, 1.2-E2E-001
- Atomic transaction testing with rollback scenarios
- Data integrity validation across save operations
- Event-violation relationship consistency checks
- End-to-end workflow validation with real data

### TECH-001: Integration Complexity with ViolationDB (Medium Risk)
**Test Coverage**: 1.2-INT-007, 1.2-INT-008, 1.2-E2E-001, 1.2-E2E-002
- CLI command integration testing
- API contract verification with ViolationDatabase
- Complete system workflow validation
- Performance comparison with legacy implementation

### TECH-002: Mapping Errors Between Models (Low Risk)
**Test Coverage**: 1.2-UNIT-001, 1.2-UNIT-006, 1.2-UNIT-003 through 1.2-UNIT-010
- Comprehensive unit testing for all field mappings
- Edge case testing with null/invalid values
- Round-trip serialization validation

## Recommended Execution Order

### Phase 1: P0 Critical Tests (Fail Fast)
1. **1.2-UNIT-001, 1.2-UNIT-002**: Core data mapping validation
2. **1.2-UNIT-006, 1.2-UNIT-007**: Violation model mapping
3. **1.2-INT-001, 1.2-INT-004**: File persistence workflows
4. **1.2-INT-002, 1.2-INT-005**: Atomic operations and data integrity

### Phase 2: P0 Integration Tests
5. **1.2-INT-007**: CLI command integration
6. **1.2-E2E-001**: End-to-end workflow validation

### Phase 3: P1 Functional Tests
7. **1.2-UNIT-003 through 1.2-UNIT-005**: Event mapping details
8. **1.2-UNIT-008 through 1.2-UNIT-010**: Violation mapping details
9. **1.2-INT-003, 1.2-INT-006, 1.2-INT-008**: Error handling scenarios
10. **1.2-E2E-002**: Performance regression testing

### Phase 4: P2 Documentation & Edge Cases
11. **1.2-UNIT-011, 1.2-UNIT-012**: Documentation validation
12. **1.2-INT-009, 1.2-INT-010**: Operational edge cases

## Test Implementation Guidelines

### Unit Test Patterns (1.2-UNIT-*)
- **Framework**: pytest with pytest-mock
- **Location**: `tests/test_legal/test_tracker.py` (extend existing file)
- **Mocking Strategy**: Mock ViolationDatabase methods, YAMNet outputs, audio file operations
- **Validation Focus**: Data field mapping accuracy, unique ID generation, classification logic

### Integration Test Patterns (1.2-INT-*)
- **Framework**: pytest with temporary directories
- **Location**: `tests/test_legal/test_tracker_integration.py` (new file)
- **Real Components**: ViolationDatabase, filesystem operations
- **Mocking Strategy**: Mock audio files, YAMNet model, but use real persistence layer
- **Validation Focus**: File creation, atomic operations, error recovery

### E2E Test Patterns (1.2-E2E-*)
- **Framework**: pytest with sample audio files
- **Location**: `tests/test_legal/test_analysis_workflow.py` (new file)
- **Real Components**: Complete analysis pipeline with sample data
- **Mocking Strategy**: Minimal - only external dependencies
- **Validation Focus**: Complete workflow, performance baselines, output quality

## Data Generation for Testing

### Sample Data Requirements
- **Audio Files**: 3-5 sample recordings with known bark patterns
- **Ground Truth**: Expected PersistedBarkEvent and Violation objects
- **Edge Cases**: Empty files, corrupted audio, invalid timestamps
- **Date Scenarios**: Multiple dates, boundary conditions

### Mock Data Patterns
- **Bark Events**: Various confidence levels, types, durations
- **Violations**: Both Constant and Intermittent types
- **Error Conditions**: File system failures, permission issues, malformed data

## Quality Checklist

Before finalizing tests, verify:

- [ ] Every AC has test coverage
- [ ] All high-risk scenarios (DATA-001) have comprehensive coverage
- [ ] Test levels are appropriate (unit for logic, integration for workflow)
- [ ] No duplicate coverage across levels
- [ ] Priorities align with risk assessment
- [ ] Test IDs follow naming convention
- [ ] Scenarios are atomic and independent
- [ ] Error conditions are properly tested
- [ ] Performance baselines are established

## Key Principles Applied

- **Risk-Driven Testing**: Heavy focus on DATA-001 mitigation through integrity testing
- **Shift Left**: Unit tests for all data mapping logic before integration testing
- **Fast Feedback**: P0 tests run first to catch critical failures early
- **Real Data Integration**: E2E tests use actual audio samples for realistic validation
- **Atomic Validation**: Each test validates a single, specific concern
- **Error-First Design**: Comprehensive error condition testing for robustness